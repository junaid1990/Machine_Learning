{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and predicting: estimator basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides dozens of built-in machine learning algorithms and models, called estimators. Each estimator can be fitted to some data using its fit method.\n",
    "\n",
    "Here is a simple example where we fit a RandomForestClassifier to some very basic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imort libararies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df= pd.read_csv(\"data/salary_data.csv\",encoding = \"Latin-1\")\n",
    "df.head()\n",
    "#assigning x and y from the dataset\n",
    "X = df.iloc[:, :-1].values #get a copy of dataset exclude last column\n",
    "y = df.iloc[:, 1].values #get array of dataset in column 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    ">>> clf = RandomForestClassifier(random_state=0)\n",
    ">>> clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the estimator is fitted, it can be used for predicting target values of new data. You don’t need to re-train the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39343,  46205,  37731,  43525,  39891,  56642,  60150,  64445,\n",
       "        64445,  57189,  63218,  55794,  55794,  57081,  61111,  67938,\n",
       "        66029,  83088,  81363,  93940,  91738,  98273, 101302, 113812,\n",
       "       109431, 105582, 116969, 112635, 122391, 121872], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> clf.predict(X)  # predict classes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122391], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> clf.predict([[10]])  # predict classes of new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers and pre-processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, pre-processors and transformers follow the same API as the estimator objects (they actually all inherit from the same BaseEstimator class). The transformer objects don’t have a predict method but rather a transform method that outputs a newly transformed sample matrix X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.51005294],\n",
       "       [-1.43837321],\n",
       "       [-1.36669348],\n",
       "       [-1.18749416],\n",
       "       [-1.11581443],\n",
       "       [-0.86493538],\n",
       "       [-0.82909552],\n",
       "       [-0.75741579],\n",
       "       [-0.75741579],\n",
       "       [-0.57821647],\n",
       "       [-0.50653674],\n",
       "       [-0.47069688],\n",
       "       [-0.47069688],\n",
       "       [-0.43485702],\n",
       "       [-0.29149756],\n",
       "       [-0.1481381 ],\n",
       "       [-0.07645838],\n",
       "       [-0.00477865],\n",
       "       [ 0.21026054],\n",
       "       [ 0.2461004 ],\n",
       "       [ 0.53281931],\n",
       "       [ 0.6403389 ],\n",
       "       [ 0.92705781],\n",
       "       [ 1.03457741],\n",
       "       [ 1.21377673],\n",
       "       [ 1.32129632],\n",
       "       [ 1.50049564],\n",
       "       [ 1.5363355 ],\n",
       "       [ 1.78721455],\n",
       "       [ 1.85889428]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.preprocessing import StandardScaler\n",
    "\n",
    ">>> # scale data according to computed scaling values\n",
    ">>> StandardScaler().fit(X).transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines: chaining pre-processors and estimator\n",
    "ransformers and estimators (predictors) can be combined together into a single unifying object: a Pipeline. The pipeline offers the same API as a regular estimator: it can be fitted and used for prediction with fit and predict. As we will see later, using a pipeline will also prevent you from data leakage, i.e. disclosing some testing data in your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "# # load the iris dataset and split it into train and test sets\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now use it like any other estimator\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "scikit-learn provides many other tools for model evaluation, in particular for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "sal = LinearRegression()\n",
    "\n",
    "result = cross_validate(sal, X, y)  # defaults to 5-fold CV\n",
    "result['test_score']  # r_squared score is high because dataset is easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic parameter searches\n",
    "Scikit-learn provides tools to automatically find the best parameter combinations (via cross-validation). In the following example, we randomly search over the parameter space of a random forest with a RandomizedSearchCV object. When the search is over, the RandomizedSearchCV behaves as a RandomForestRegressor that has been fitted with the best set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# define the parameter space that will be searched over\n",
    "param_distributions = {'n_estimators': randint(1, 5),\n",
    "                       'max_depth': randint(5, 10)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now create a searchCV object and fit it to the data\n",
    "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
    "                            n_iter=5,\n",
    "                            param_distributions=param_distributions,\n",
    "                            random_state=0)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7357088178446147"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the search object now acts like a normal random forest estimator\n",
    "# with max_depth=9 and n_estimators=4\n",
    "search.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1. Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.36693293e-01,  9.43577803e-03, -1.07322041e-01,  6.45065694e-01,\n",
       "       -3.97638942e-06, -3.78654265e-03, -4.21314378e-01, -4.34513755e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X,y)\n",
    "\n",
    "reg.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2. Ridge regression and classification\n",
    "### 1.1.2.1. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.36643796e-01,  9.43658673e-03, -1.07227325e-01,  6.44563694e-01,\n",
       "       -3.97336560e-06, -3.78645054e-03, -4.21306864e-01, -4.34499254e-01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha=.5)\n",
    "reg.fit(X,y)\n",
    "\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-36.94025397892831"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "db9da9d256f457015986a8acd5c7819a5914eb9a575ecff51b37f60a7d912a81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
